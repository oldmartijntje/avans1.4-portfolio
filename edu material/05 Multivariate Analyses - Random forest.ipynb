{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a408090f-4d94-4646-9979-8a902742cc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145fd92e-b7f2-47a5-b11a-635ff3d71bd1",
   "metadata": {},
   "source": [
    "# Random Forest\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251c4a4d-9376-4cf8-8780-3fff21ee9d7c",
   "metadata": {},
   "source": [
    "Random Forest is one of the most popular and most powerful machine learning algorithms. It is a type of ensemble machine learning algorithm called Bootstrap Aggregation or bagging. <b>\n",
    "\n",
    "![](https://miro.medium.com/v2/resize:fit:640/format:webp/1*i0o8mjFfCn-uD79-F1Cqkw.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d5b281-0752-4744-8652-221059cbf506",
   "metadata": {},
   "source": [
    "We will apply a Random Forest classifier to the task of classifying penguin species. To optimize performance and accuracy, we will focus on two key parameters: max_depth and n_estimators.\n",
    "\n",
    "- n_estimators: number of trees in the forest\n",
    "- max_depth: controls how deep each decision tree can grow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6214dbe4-a9a3-4dd8-b029-29df46a5142a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c091ea79-77d0-4aa8-a427-4d58f3d98c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins = sns.load_dataset(\"penguins\")\n",
    "penguins = penguins.fillna(0)\n",
    "print(penguins.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f992c93c-6d60-4169-b262-743c36c63431",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['bill_length_mm', 'body_mass_g', \"flipper_length_mm\"] #add features per iteration such as 'body_mass_g'\n",
    "X = penguins[features]\n",
    "y = penguins['species']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d771cbb-0896-4d3c-bf66-48b0ccb6bc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3fc775-8c8f-4fef-b5c3-74303ce22e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(criterion='entropy', n_estimators=5, max_depth=3)\n",
    "rf.fit(X_train, y_train) #fit the random forest to the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35132091",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install fpdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9772626f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "import graphviz\n",
    "from fpdf import FPDF\n",
    "\n",
    "def plot_tree_classification(model, features, class_names, output_file='random_forest'):  \n",
    "    if isinstance(model, RandomForestClassifier):\n",
    "        pdf = FPDF()\n",
    "\n",
    "        for i, tree_model in enumerate(model.estimators_):\n",
    "            dot_data = tree.export_graphviz(tree_model, out_file=None, \n",
    "                                  feature_names=features,  \n",
    "                                  class_names=class_names,  \n",
    "                                  filled=True, rounded=True,  \n",
    "                                  special_characters=True)  \n",
    "\n",
    "            # Turn into graph using graphviz\n",
    "            graph = graphviz.Source(dot_data)  \n",
    "\n",
    "            # Save as PNG for embedding in PDF\n",
    "            image_file = f\"{output_file}_tree_{i+1}.png\"\n",
    "            graph.render(filename=image_file, format='png')\n",
    "\n",
    "            # Add each tree image to PDF\n",
    "            pdf.add_page()\n",
    "            pdf.image(image_file + '.png', x=10, y=10, w=180)\n",
    "\n",
    "        # Save the complete PDF\n",
    "        pdf_output_file = f\"{output_file}.pdf\"\n",
    "        pdf.output(pdf_output_file)\n",
    "\n",
    "        print(f\"All trees saved in {pdf_output_file}.\")\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"The model is not a RandomForestClassifier.\")                                \n",
    "    \n",
    "    return graph\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c26d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = X.columns\n",
    "class_names = np.sort(np.unique(y)).astype(str)\n",
    "plot_tree_classification(rf, feature_names, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b965799-d092-4631-9613-4a34a9fa17fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(predictions, actuals):\n",
    "    if(len(predictions) != len(actuals)):\n",
    "        raise Exception(\"The amount of predictions did not equal the amount of actuals\")\n",
    "    \n",
    "    return (predictions == actuals).sum() / len(actuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35674da3-53a3-4735-8085-c17ae1f1b862",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionsOnTrainset = rf.predict(X_train)\n",
    "predictionsOnTestset = rf.predict(X_test)\n",
    "\n",
    "accuracyTrain = calculate_accuracy(predictionsOnTrainset, y_train)\n",
    "accuracyTest = calculate_accuracy(predictionsOnTestset, y_test)\n",
    "\n",
    "print(\"Accuracy on training set \" + str(accuracyTrain))\n",
    "print(\"Accuracy on test set \" + str(accuracyTest))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e92c84e-e4a8-44ce-96cf-4ec855718ef8",
   "metadata": {},
   "source": [
    "## Portfolio assignment 19\n",
    "30 min: Train a random forest to predict one of the categorical columns of your **own** dataset.\n",
    "- Prepare the data:<br>\n",
    "    - <b>Note</b>: Some machine learning algorithms can not handle missing values. You will either need to: \n",
    "         - replace missing values (with the mean or most popular value). For replacing missing values you can use .fillna(\\<value\\>) https://pandas.pydata.org/docs/reference/api/pandas.Series.fillna.html\n",
    "         - remove rows with missing data.  You can remove rows with missing data with .dropna() https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.dropna.html <br>\n",
    "- Split your dataset into a train (70%) and test (30%) set.\n",
    "- Use the train set to fit a RandomForestClassifier. You are free to to choose which columns you want to use as feature variables and you are also free to choose the max_depth of the tree. \n",
    "- Use your random forest model to make predictions for both the train and test set.\n",
    "<br>\n",
    "    \n",
    "![](https://i.imgur.com/0v1CGNV.png)<br>\n",
    "- Calculate the accuracy for both the train set predictions and test set predictions.\n",
    "- Is the accurracy different? Did you expect this difference?\n",
    "- Which number of trees, depth and features did you add per cycle?\n",
    "- Is the accurracy different? Did you expect this difference?\n",
    "\n",
    "\n",
    "\n",
    "Findings: ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
