{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7b8c5890-558c-4f33-90fb-eeaf0e99cdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "# Ignore the ConvergenceWarning\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ee88e7a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: jupyter in c:\\users\\emile\\anaconda3\\envs\\datascience\\lib\\site-packages (from -r requirements.txt (line 1)) (1.1.1)\n",
      "Requirement already satisfied: notebook in c:\\users\\emile\\anaconda3\\envs\\datascience\\lib\\site-packages (from -r requirements.txt (line 2)) (7.3.3)\n",
      "Requirement already satisfied: pandas in c:\\users\\emile\\anaconda3\\envs\\datascience\\lib\\site-packages (from -r requirements.txt (line 3)) (2.2.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\emile\\anaconda3\\envs\\datascience\\lib\\site-packages (from -r requirements.txt (line 4)) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\emile\\anaconda3\\envs\\datascience\\lib\\site-packages (from -r requirements.txt (line 5)) (1.15.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\emile\\anaconda3\\envs\\datascience\\lib\\site-packages (from -r requirements.txt (line 6)) (3.10.1)\n",
      "Requirement already satisfied: seaborn in c:\\users\\emile\\anaconda3\\envs\\datascience\\lib\\site-packages (from -r requirements.txt (line 7)) (0.13.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\emile\\anaconda3\\envs\\datascience\\lib\\site-packages (from -r requirements.txt (line 8)) (1.6.1)\n",
      "Requirement already satisfied: graphviz in c:\\users\\emile\\anaconda3\\envs\\datascience\\lib\\site-packages (from -r requirements.txt (line 9)) (0.20.3)\n",
      "Requirement already satisfied: dtreeviz in c:\\users\\emile\\anaconda3\\envs\\datascience\\lib\\site-packages (from -r requirements.txt (line 10)) (2.2.2)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\emile\\anaconda3\\envs\\datascience\\lib\\site-packages (from -r requirements.txt (line 11)) (4.10.0.84)\n",
      "Requirement already satisfied: jupyter-console in c:\\users\\emile\\anaconda3\\envs\\datascience\\lib\\site-packages (from jupyter->-r requirements.txt (line 1)) (6.6.3)\n",
      "Requirement already satisfied: nbconvert in c:\\users\\emile\\anaconda3\\envs\\datascience\\lib\\site-packages (from jupyter->-r requirements.txt (line 1)) (7.16.6)\n",
      "Requirement already satisfied: ipykernel in c:\\users\\emile\\anaconda3\\envs\\datascience\\lib\\site-packages (from jupyter->-r requirements.txt (line 1)) (6.29.5)\n",
      "Requirement already satisfied: ipywidgets in c:\\users\\emile\\anaconda3\\envs\\datascience\\lib\\site-packages (from jupyter->-r requirements.txt (line 1)) (8.1.5)\n",
      "Requirement already satisfied: jupyterlab in c:\\users\\emile\\anaconda3\\envs\\datascience\\lib\\site-packages (from jupyter->-r requirements.txt (line 1)) (4.3.6)\n",
      "Requirement already satisfied: jupyter-server<3,>=2.4.0 in c:\\users\\emile\\anaconda3\\envs\\datascience\\lib\\site-packages (from notebook->-r requirements.txt (line 2)) (2.15.0)\n",
      "Requirement already satisfied: jupyterlab-server<3,>=2.27.1 in c:\\users\\emile\\anaconda3\\envs\\datascience\\lib\\site-packages (from notebook->-r requirements.txt (line 2)) (2.27.3)\n",
      "Requirement already satisfied: notebook-shim<0.3,>=0.2 in c:\\users\\emile\\anaconda3\\envs\\datascience\\lib\\site-packages (from notebook->-r requirements.txt (line 2)) (0.2.4)\n",
      "Requirement already satisfied: tornado>=6.2.0 in c:\\users\\emile\\anaconda3\\envs\\datascience\\lib\\site-packages (from notebook->-r requirements.txt (line 2)) (6.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\emile\\anaconda3\\envs\\datascience\\lib\\site-packages (from pandas->-r requirements.txt (line 3)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\emile\\anaconda3\\envs\\datascience\\lib\\site-packages (from pandas->-r requirements.txt (line 3)) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\emile\\anaconda3\\envs\\datascience\\lib\\site-packages (from pandas->-r requirements.txt (line 3)) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\emile\\anaconda3\\envs\\datascience\\lib\\site-packages (from matplotlib->-r requirements.txt (line 6)) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\emile\\anaconda3\\envs\\datascience\\lib\\site-packages (from matplotlib->-r requirements.txt (line 6)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\emile\\anaconda3\\envs\\datascience\\lib\\site-packages (from matplotlib->-r requirements.txt (line 6)) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\emile\\anaconda3\\envs\\datascience\\lib\\site-packages (from matplotlib->-r requirements.txt (line 6)) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\emile\\anaconda3\\envs\\datascience\\lib\\site-packages (from matplotlib->-r requirements.txt (line 6)) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\emile\\anaconda3\\envs\\datascience\\lib\\site-packages (from matplotlib->-r requirements.txt (line 6)) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\emile\\anaconda3\\envs\\datascience\\lib\\site-packages (from matplotlib->-r requirements.txt (line 6)) (3.2.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\emile\\anaconda3\\envs\\datascience\\lib\\site-packages (from scikit-learn->-r requirements.txt (line 8)) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\emile\\anaconda3\\envs\\datascience\\lib\\site-packages (from scikit-learn->-r requirements.txt (line 8)) (3.6.0)\n",
      "Requirement already satisfied: colour in c:\\users\\emile\\anaconda3\\envs\\datascience\\lib\\site-packages (from dtreeviz->-r requirements.txt (line 10)) (0.1.5)\n",
      "Requirement already satisfied: pytest in c:\\users\\emile\\anaconda3\\envs\\datascience\\lib\\site-packages (from dtreeviz->-r requirements.txt (line 10)) (8.3.5)\n",
      "Requirement already satisfied: anyio>=3.1.0 in c:\\users\\emile\\anaconda3\\envs\\datascience\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->-r requirements.txt (line 2)) (4.9.0)\n",
      "Requirement already satisfied: argon2-cffi>=21.1 in c:\\users\\emile\\anaconda3\\envs\\datascience\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->-r requirements.txt (line 2)) (23.1.0)\n",
      "Requirement already satisfied: jinja2>=3.0.3 in c:\\users\\emile\\anaconda3\\envs\\datascience\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->-r requirements.txt (line 2)) (3.1.6)\n",
      "Requirement already satisfied: jupyter-client>=7.4.4 in c:\\users\\emile\\anaconda3\\envs\\datascience\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->-r requirements.txt (line 2)) (8.6.3)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in c:\\users\\emile\\anaconda3\\envs\\datascience\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->-r requirements.txt (line 2)) (5.7.2)\n",
      "Requirement already satisfied: jupyter-events>=0.11.0 in c:\\users\\emile\\anaconda3\\envs\\datascience\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->-r requirements.txt (line 2)) (0.12.0)\n",
      "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in c:\\users\\emile\\anaconda3\\envs\\datascience\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->-r requirements.txt (line 2)) (0.5.3)\n",
      "Requirement already satisfied: nbformat>=5.3.0 in c:\\users\\emile\\anaconda3\\envs\\datascience\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->-r requirements.txt (line 2)) (5.10.4)\n",
      "Requirement already satisfied: overrides>=5.0 in c:\\users\\emile\\anaconda3\\envs\\datascience\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->-r requirements.txt (line 2)) (7.7.0)\n",
      "Requirement already satisfied: prometheus-client>=0.9 in c:\\users\\emile\\anaconda3\\envs\\datascience\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->-r requirements.txt (line 2)) (0.21.1)\n",
      "Requirement already satisfied: pywinpty>=2.0.1 in c:\\users\\emile\\anaconda3\\envs\\datascience\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->-r requirements.txt (line 2)) (2.0.15)\n",
      "Requirement already satisfied: pyzmq>=24 in c:\\users\\emile\\anaconda3\\envs\\datascience\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->-r requirements.txt (line 2)) (26.3.0)\n",
      "Requirement already satisfied: send2trash>=1.8.2 in c:\\users\\emile\\anaconda3\\envs\\datascience\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->-r requirements.txt (line 2)) (1.8.3)\n",
      "Requirement already satisfied: terminado>=0.8.3 in c:\\users\\emile\\anaconda3\\envs\\datascience\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->-r requirements.txt (line 2)) (0.18.1)\n",
      "Requirement already satisfied: traitlets>=5.6.0 in c:\\users\\emile\\anaconda3\\envs\\datascience\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->-r requirements.txt (line 2)) (5.14.3)\n",
      "Requirement already satisfied: websocket-client>=1.7 in c:\\users\\emile\\anaconda3\\envs\\datascience\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->-r requirements.txt (line 2)) (1.8.0)\n",
      "Requirement already satisfied: async-lru>=1.0.0 in c:\\users\\emile\\anaconda3\\envs\\datascience\\lib\\site-packages (from jupyterlab->jupyter->-r requirements.txt (line 1)) (2.0.5)\n",
      "Requirement already satisfied: httpx>=0.25.0 in c:\\users\\emile\\anaconda3\\envs\\datascience\\lib\\site-packages (from jupyterlab->jupyter->-r requirements.txt (line 1)) (0.28.1)\n",
      "Requirement already satisfied: jupyter-lsp>=2.0.0 in c:\\users\\emile\\anaconda3\\envs\\datascience\\lib\\site-packages (from jupyterlab->jupyter->-r requirements.txt (line 1)) (2.2.5)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in c:\\users\\emile\\anaconda3\\envs\\datascience\\lib\\site-packages (from jupyterlab->jupyter->-r requirements.txt (line 1)) (75.8.0)\n",
      "Requirement already satisfied: comm>=0.1.1 in c:\\users\\emile\\anaconda3\\envs\\datascience\\lib\\site-packages (from ipykernel->jupyter->-r requirements.txt (line 1)) (0.2.2)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in c:\\users\\emile\\anaconda3\\envs\\datascience\\lib\\site-packages (from ipykernel->jupyter->-r requirements.txt (line 1)) (1.8.13)\n",
      "Requirement already satisfied: ipython>=7.23.1 in c:\\users\\emile\\anaconda3\\envs\\datascience\\lib\\site-packages (from ipykernel->jupyter->-r requirements.txt (line 1)) (9.0.2)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in c:\\users\\emile\\anaconda3\\envs\\datascience\\lib\\site-packages (from ipykernel->jupyter->-r requirements.txt (line 1)) (0.1.7)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\emile\\anaconda3\\envs\\datascience\\lib\\site-packages (from ipykernel->jupyter->-r requirements.txt (line 1)) (1.6.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\emile\\anaconda3\\envs\\datascience\\lib\\site-packages (from ipykernel->jupyter->-r requirements.txt (line 1)) (7.0.0)\n",
      "Requirement already satisfied: babel>=2.10 in c:\\users\\emile\\anaconda3\\envs\\datascience\\lib\\site-packages (from jupyterlab-server<3,>=2.27.1->notebook->-r requirements.txt (line 2)) (2.17.0)\n",
      "Requirement already satisfied: json5>=0.9.0 in c:\\users\\emile\\anaconda3\\envs\\datascience\\lib\\site-packages (from jupyterlab-server<3,>=2.27.1->notebook->-r requirements.txt (line 2)) (0.10.0)\n",
      "Requirement already satisfied: jsonschema>=4.18.0 in c:\\users\\emile\\anaconda3\\envs\\datascience\\lib\\site-packages (from jupyterlab-server<3,>=2.27.1->notebook->-r requirements.txt (line 2)) (4.23.0)\n",
      "Requirement already satisfied: requests>=2.31 in c:\\users\\emile\\anaconda3\\envs\\datascience\\lib\\site-packages (from jupyterlab-server<3,>=2.27.1->notebook->-r requirements.txt (line 2)) (2.32.3)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\emile\\anaconda3\\envs\\datascience\\lib\\site-packages (from nbconvert->jupyter->-r requirements.txt (line 1)) (4.13.3)\n",
      "Requirement already satisfied: bleach!=5.0.0 in c:\\users\\emile\\anaconda3\\envs\\datascience\\lib\\site-packages (from bleach[css]!=5.0.0->nbconvert->jupyter->-r requirements.txt (line 1)) (6.2.0)\n",
      "Requirement already satisfied: defusedxml in c:\\users\\emile\\anaconda3\\envs\\datascience\\lib\\site-packages (from nbconvert->jupyter->-r requirements.txt (line 1)) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in c:\\users\\emile\\anaconda3\\envs\\datascience\\lib\\site-packages (from nbconvert->jupyter->-r requirements.txt (line 1)) (0.3.0)\n",
      "Requirement already satisfied: markupsafe>=2.0 in c:\\users\\emile\\anaconda3\\envs\\datascience\\lib\\site-packages (from nbconvert->jupyter->-r requirements.txt (line 1)) (3.0.2)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in c:\\users\\emile\\anaconda3\\envs\\datascience\\lib\\site-packages (from nbconvert->jupyter->-r requirements.txt (line 1)) (3.1.3)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in c:\\users\\emile\\anaconda3\\envs\\datascience\\lib\\site-packages (from nbconvert->jupyter->-r requirements.txt (line 1)) (0.10.2)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in c:\\users\\emile\\anaconda3\\envs\\datascience\\lib\\site-packages (from nbconvert->jupyter->-r requirements.txt (line 1)) (1.5.1)\n",
      "Requirement already satisfied: pygments>=2.4.1 in c:\\users\\emile\\anaconda3\\envs\\datascience\\lib\\site-packages (from nbconvert->jupyter->-r requirements.txt (line 1)) (2.19.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\emile\\anaconda3\\envs\\datascience\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->-r requirements.txt (line 3)) (1.17.0)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.12 in c:\\users\\emile\\anaconda3\\envs\\datascience\\lib\\site-packages (from ipywidgets->jupyter->-r requirements.txt (line 1)) (4.0.13)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in c:\\users\\emile\\anaconda3\\envs\\datascience\\lib\\site-packages (from ipywidgets->jupyter->-r requirements.txt (line 1)) (3.0.13)\n",
      "Requirement already satisfied: prompt-toolkit>=3.0.30 in c:\\users\\emile\\anaconda3\\envs\\datascience\\lib\\site-packages (from jupyter-console->jupyter->-r requirements.txt (line 1)) (3.0.50)\n",
      "Requirement already satisfied: colorama in c:\\users\\emile\\anaconda3\\envs\\datascience\\lib\\site-packages (from pytest->dtreeviz->-r requirements.txt (line 10)) (0.4.6)\n",
      "Requirement already satisfied: iniconfig in c:\\users\\emile\\anaconda3\\envs\\datascience\\lib\\site-packages (from pytest->dtreeviz->-r requirements.txt (line 10)) (2.1.0)\n",
      "Requirement already satisfied: pluggy<2,>=1.5 in c:\\users\\emile\\anaconda3\\envs\\datascience\\lib\\site-packages (from pytest->dtreeviz->-r requirements.txt (line 10)) (1.5.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\emile\\anaconda3\\envs\\datascience\\lib\\site-packages (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->notebook->-r requirements.txt (line 2)) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\emile\\anaconda3\\envs\\datascience\\lib\\site-packages (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->notebook->-r requirements.txt (line 2)) (1.3.1)\n",
      "Requirement already satisfied: typing_extensions>=4.5 in c:\\users\\emile\\anaconda3\\envs\\datascience\\lib\\site-packages (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->notebook->-r requirements.txt (line 2)) (4.13.0)\n",
      "Requirement already satisfied: argon2-cffi-bindings in c:\\users\\emile\\anaconda3\\envs\\datascience\\lib\\site-packages (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->notebook->-r requirements.txt (line 2)) (21.2.0)\n",
      "Requirement already satisfied: webencodings in c:\\users\\emile\\anaconda3\\envs\\datascience\\lib\\site-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert->jupyter->-r requirements.txt (line 1)) (0.5.1)\n",
      "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in c:\\users\\emile\\anaconda3\\envs\\datascience\\lib\\site-packages (from bleach[css]!=5.0.0->nbconvert->jupyter->-r requirements.txt (line 1)) (1.4.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\emile\\anaconda3\\envs\\datascience\\lib\\site-packages (from httpx>=0.25.0->jupyterlab->jupyter->-r requirements.txt (line 1)) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\emile\\anaconda3\\envs\\datascience\\lib\\site-packages (from httpx>=0.25.0->jupyterlab->jupyter->-r requirements.txt (line 1)) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\emile\\anaconda3\\envs\\datascience\\lib\\site-packages (from httpcore==1.*->httpx>=0.25.0->jupyterlab->jupyter->-r requirements.txt (line 1)) (0.14.0)\n",
      "Requirement already satisfied: decorator in c:\\users\\emile\\anaconda3\\envs\\datascience\\lib\\site-packages (from ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 1)) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in c:\\users\\emile\\anaconda3\\envs\\datascience\\lib\\site-packages (from ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 1)) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\emile\\anaconda3\\envs\\datascience\\lib\\site-packages (from ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 1)) (0.19.2)\n",
      "Requirement already satisfied: stack_data in c:\\users\\emile\\anaconda3\\envs\\datascience\\lib\\site-packages (from ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 1)) (0.6.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\emile\\anaconda3\\envs\\datascience\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->notebook->-r requirements.txt (line 2)) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\emile\\anaconda3\\envs\\datascience\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->notebook->-r requirements.txt (line 2)) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\emile\\anaconda3\\envs\\datascience\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->notebook->-r requirements.txt (line 2)) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\emile\\anaconda3\\envs\\datascience\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->notebook->-r requirements.txt (line 2)) (0.24.0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\emile\\anaconda3\\envs\\datascience\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->jupyter-server<3,>=2.4.0->notebook->-r requirements.txt (line 2)) (4.3.7)\n",
      "Requirement already satisfied: pywin32>=300 in c:\\users\\emile\\anaconda3\\envs\\datascience\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->jupyter-server<3,>=2.4.0->notebook->-r requirements.txt (line 2)) (310)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in c:\\users\\emile\\anaconda3\\envs\\datascience\\lib\\site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook->-r requirements.txt (line 2)) (3.3.0)\n",
      "Requirement already satisfied: pyyaml>=5.3 in c:\\users\\emile\\anaconda3\\envs\\datascience\\lib\\site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook->-r requirements.txt (line 2)) (6.0.2)\n",
      "Requirement already satisfied: rfc3339-validator in c:\\users\\emile\\anaconda3\\envs\\datascience\\lib\\site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook->-r requirements.txt (line 2)) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in c:\\users\\emile\\anaconda3\\envs\\datascience\\lib\\site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook->-r requirements.txt (line 2)) (0.1.1)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in c:\\users\\emile\\anaconda3\\envs\\datascience\\lib\\site-packages (from nbformat>=5.3.0->jupyter-server<3,>=2.4.0->notebook->-r requirements.txt (line 2)) (2.21.1)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\emile\\anaconda3\\envs\\datascience\\lib\\site-packages (from prompt-toolkit>=3.0.30->jupyter-console->jupyter->-r requirements.txt (line 1)) (0.2.13)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\emile\\anaconda3\\envs\\datascience\\lib\\site-packages (from requests>=2.31->jupyterlab-server<3,>=2.27.1->notebook->-r requirements.txt (line 2)) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\emile\\anaconda3\\envs\\datascience\\lib\\site-packages (from requests>=2.31->jupyterlab-server<3,>=2.27.1->notebook->-r requirements.txt (line 2)) (2.3.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\emile\\anaconda3\\envs\\datascience\\lib\\site-packages (from beautifulsoup4->nbconvert->jupyter->-r requirements.txt (line 1)) (2.6)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\users\\emile\\anaconda3\\envs\\datascience\\lib\\site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 1)) (0.8.4)\n",
      "Requirement already satisfied: fqdn in c:\\users\\emile\\anaconda3\\envs\\datascience\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook->-r requirements.txt (line 2)) (1.5.1)\n",
      "Requirement already satisfied: isoduration in c:\\users\\emile\\anaconda3\\envs\\datascience\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook->-r requirements.txt (line 2)) (20.11.0)\n",
      "Requirement already satisfied: jsonpointer>1.13 in c:\\users\\emile\\anaconda3\\envs\\datascience\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook->-r requirements.txt (line 2)) (3.0.0)\n",
      "Requirement already satisfied: uri-template in c:\\users\\emile\\anaconda3\\envs\\datascience\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook->-r requirements.txt (line 2)) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=24.6.0 in c:\\users\\emile\\anaconda3\\envs\\datascience\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook->-r requirements.txt (line 2)) (24.11.1)\n",
      "Requirement already satisfied: cffi>=1.0.1 in c:\\users\\emile\\anaconda3\\envs\\datascience\\lib\\site-packages (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->notebook->-r requirements.txt (line 2)) (1.17.1)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\emile\\anaconda3\\envs\\datascience\\lib\\site-packages (from stack_data->ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 1)) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\emile\\anaconda3\\envs\\datascience\\lib\\site-packages (from stack_data->ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 1)) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\emile\\anaconda3\\envs\\datascience\\lib\\site-packages (from stack_data->ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 1)) (0.2.3)\n",
      "Requirement already satisfied: pycparser in c:\\users\\emile\\anaconda3\\envs\\datascience\\lib\\site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->notebook->-r requirements.txt (line 2)) (2.22)\n",
      "Requirement already satisfied: arrow>=0.15.0 in c:\\users\\emile\\anaconda3\\envs\\datascience\\lib\\site-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook->-r requirements.txt (line 2)) (1.3.0)\n",
      "Requirement already satisfied: types-python-dateutil>=2.8.10 in c:\\users\\emile\\anaconda3\\envs\\datascience\\lib\\site-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook->-r requirements.txt (line 2)) (2.9.0.20241206)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd4350c-5285-4985-b6cd-d1b0f574f3ed",
   "metadata": {},
   "source": [
    "# Artificial Neural Networks \n",
    "\n",
    "## About this notebook\n",
    "\n",
    "This notebook kernel was created to help you understand more about machine learning. I intend to create tutorials with several machine learning algorithms from basic to advanced. I hope I can help you with this data science trail. For any information, you can contact me through the link below.\n",
    "\n",
    "Contact me here: https://www.linkedin.com/in/vitorgamalemos/\n",
    "\n",
    "## Introduction \n",
    "\n",
    "<img src=\"https://media.springernature.com/original/springer-static/image/art%3A10.1007%2Fs40846-016-0191-3/MediaObjects/40846_2016_191_Fig1_HTML.gif\">\n",
    "\n",
    "<p style=\"text-align: justify;\">Artificial Neural Networks are mathematical models inspired by the human brain, specifically the ability to learn, process, and perform tasks. The Artificial Neural Networks are powerful tools that assist in solving complex problems linked mainly in the area of combinatorial optimization and machine learning. In this context, artificial neural networks have the most varied applications possible, as such models can adapt to the situations presented, ensuring a gradual increase in performance without any human interference. We can say that the Artificial Neural Networks are potent methods can give computers a new possibility, that is, a machine does not get stuck to preprogrammed rules and opens up various options to learn from its own mistakes.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5ea60e-cf16-46fa-9335-197f00b53f73",
   "metadata": {},
   "source": [
    "## Biologic Model\n",
    "\n",
    "<img src=\"https://www.neuroskills.com/images/photo-500x500-neuron.png\">\n",
    "<p style=\"text-align: justify;\">Artificial neurons are designed to mimic aspects of their biological counterparts. The neuron is one of the fundamental units that make up the entire brain structure of the central nervous system; such cells are responsible for transmitting information through the electrical potential difference in their membrane. In this context, a biological neuron can be divided as follows.</p>\n",
    "\n",
    "**Dendrites** – are thin branches located in the nerve cell. These cells act on receiving nerve input from other parts of our body.\n",
    "\n",
    "**Soma** – acts as a summation function. As positive and negative signals (exciting and inhibiting, respectively) arrive in the soma from the dendrites they are added together.\n",
    "\n",
    "**Axon** – gets its signal from the summation behavior which occurs inside the soma. It is formed by a single extended filament located throughout the neuron. The axon is responsible for sending nerve impulses to the external environment of a cell."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42de27de-036c-446f-940b-c7ab943cbca5",
   "metadata": {},
   "source": [
    "## Artificial Neuron as Mathematic Notation\n",
    "In general terms, an input X is multiplied by a weight W and added a bias b producing the net activation. \n",
    "<img style=\"max-width:60%;max-height:60%;\" src=\"https://miro.medium.com/max/1290/1*-JtN9TWuoZMz7z9QKbT85A.png\">\n",
    "\n",
    "We can summarize an artificial neuron with the following mathematical expression:\n",
    "$$\n",
    "\\hat{y} = f\\left(\\text{net}\\right)= f\\left(\\vec{w}\\cdot\\vec{x}+b\\right) = f\\left(\\sum_{i=1}^{n}{w_i x_i + b}\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1073dc3b-0cd9-425c-87ea-aec322435563",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## The Singlelayer Perceptron\n",
    "\n",
    "<p style=\"text-align: justify;\">The Perceptron and its learning algorithm pioneered the research in neurocomputing. the perceptron is an algorithm for supervised learning of binary classifiers [1]. A binary classifier is a function which can decide whether or not an input, represented by a vector of numbers, belongs to some specific class. It is a type of linear classifier, i.e. a classification algorithm that makes its predictions based on a linear predictor function combining a set of weights with the feature vector.<p>\n",
    "    \n",
    "<img src=\"https://www.edureka.co/blog/wp-content/uploads/2017/12/Perceptron-Learning-Algorithm_03.gif\">\n",
    "    \n",
    "#### References\n",
    "    \n",
    "- Freund, Y.; Schapire, R. E. (1999). \"Large margin classification using the perceptron algorithm\" (PDF). Machine Learning\n",
    "\n",
    "- Aizerman, M. A.; Braverman, E. M.; Rozonoer, L. I. (1964). \"Theoretical foundations of the potential function method in pattern recognition learning\". Automation and Remote Control. 25: 821–837.\n",
    " \n",
    "- Mohri, Mehryar and Rostamizadeh, Afshin (2013). Perceptron Mistake Bounds.\n",
    "\n",
    "Source: https://www.kaggle.com/code/vitorgamalemos/perceptron-neural-network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9edccc-3bc7-400f-9b6a-96d2c9ac9580",
   "metadata": {},
   "source": [
    "## Training a Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e6edd5-0ed0-417d-b05d-47d20e46b489",
   "metadata": {},
   "source": [
    "We are going to use a Perceptron from the `sklearn` library to build a simple classification model. We make use of a MultiLayerPerceptron as the name suggest in default it has multiple layers (100). In this excercise we bring this down to a perceptron which is basically a MLP with only one layer, so the variable 'hidden_layer_sizes' will be 1.  \n",
    "Before training, we must prepare the data by applying Standard Scaling (to normalize the data) and One-Hot Encoding (to convert categorical values into a format suitable for the model).  \n",
    "\n",
    "##### 1. Data Preprocessing\n",
    "- One-Hot Encoding converts categorical features into a numerical format by creating binary columns for each category.\n",
    "- Standard scaling transforms features to have a mean of 0 and a standard deviation of 1. This normalization step is crucial for models like Perceptron, which are sensitive to varying scales in input data. Without scaling, features with larger magnitudes can dominate the learning process, leading to poor model performance.\n",
    "\n",
    "##### 2. Splitting the Data\n",
    "Like with Decision Trees or Random Forests, we split our dataset into training and test sets to evaluate model performance.\n",
    "\n",
    "##### 3. Training the Perceptron\n",
    "We initialize the Perceptron model and train it using gradient descent.  \n",
    "The two key parameters we start fine-tuning with are:\n",
    "\n",
    "###### Learning Rate (`eta0`)\n",
    "- Controls how much the model updates its weights during training.\n",
    "- **High learning rate:** Fast convergence, but may overshoot optimal weights.\n",
    "- **Low learning rate:** More stable, but slow training.\n",
    "\n",
    "###### Epochs (`max_iter`)\n",
    "- Defines the number of passes over the dataset during training.\n",
    "- More epochs allow the model to learn better, but too many can cause overfitting.\n",
    "\n",
    "##### 4. Fine-Tuning the Model\n",
    "After training, we can fine-tune hyperparameters like:\n",
    "- Learning rate (`eta0`)\n",
    "- Epochs (`max_iter`)\n",
    "\n",
    "By adjusting these parameters, we aim to improve accuracy and generalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "486a13c1-ff7e-45d6-8514-880a88286ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b0d6c4b1-138e-4a07-a910-a57e49fcc8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Iris dataset\n",
    "data = load_iris()\n",
    "X = data.data\n",
    "y = data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "15b5b8ca-50a9-4e25-addb-164f0ae378b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the data (scale the features)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e5562e30-f5d0-4799-af89-31697f388672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909c6f14-0f33-4149-b1f7-12cde9921dc1",
   "metadata": {},
   "source": [
    "#### Iteration 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5324b673-ce5e-4547-b1e6-9c63d4471e02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.3583\n",
      "Test Accuracy: 0.3333\n"
     ]
    }
   ],
   "source": [
    "# Set the learning rate, max_iter, and hidden layer sizes as specified\n",
    "learning_rate = 0.001\n",
    "max_iter = 5 # from 5 to 40\n",
    "hidden_layer_sizes = 1\n",
    "\n",
    "# Initialize the MLPClassifier with the given hyperparameters\n",
    "model = MLPClassifier(\n",
    "    hidden_layer_sizes=hidden_layer_sizes,\n",
    "    learning_rate_init=learning_rate,\n",
    "    max_iter=max_iter,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the training set\n",
    "y_train_pred = model.predict(X_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy for both training and test sets\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1814f3a-b526-465a-b34d-c6d83b8a253e",
   "metadata": {},
   "source": [
    "#### Iteration 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4ae8fc00-5031-4908-8510-23828bbd3fb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.4583\n",
      "Test Accuracy: 0.4333\n"
     ]
    }
   ],
   "source": [
    "# Set the learning rate, max_iter, and hidden layer sizes as specified\n",
    "learning_rate = 0.05 # from 0.001 to 0.1 like 0.01 or 0.05 \n",
    "max_iter = 4 \n",
    "hidden_layer_sizes = 1\n",
    "\n",
    "# Initialize the MLPClassifier with the given hyperparameters\n",
    "model = MLPClassifier(\n",
    "    hidden_layer_sizes=hidden_layer_sizes,\n",
    "    learning_rate_init=learning_rate,\n",
    "    max_iter=max_iter,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the training set\n",
    "y_train_pred = model.predict(X_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy for both training and test sets\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d897e171-6a9f-4292-9512-52033ef8c8aa",
   "metadata": {},
   "source": [
    "#### Iteration 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c3412fbd-0412-4593-9165-62d27a7c4f4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.9750\n",
      "Test Accuracy: 0.9667\n"
     ]
    }
   ],
   "source": [
    "# Set the learning rate, max_iter, and hidden layer sizes as specified\n",
    "learning_rate = 0.1\n",
    "max_iter = 50\n",
    "hidden_layer_sizes = 1\n",
    "\n",
    "# Initialize the MLPClassifier with the given hyperparameters\n",
    "model = MLPClassifier(\n",
    "    hidden_layer_sizes=hidden_layer_sizes,\n",
    "    learning_rate_init=learning_rate,\n",
    "    max_iter=max_iter,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the training set\n",
    "y_train_pred = model.predict(X_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy for both training and test sets\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d5178f-d5f6-4113-be4e-9613a3aed107",
   "metadata": {},
   "source": [
    "### Portfolio assignment 20\n",
    "30 min: Train a perceptron to predict the number of the MNIST dataset.\n",
    "- Fit a Perceptron model (keep hidden_layer_sizes=1) using the images in de fetch openml dataset.\n",
    "- Change the learning_rate and max_iter to find the 'right fit'.\n",
    "- Use your perceptron to make predictions for both the train and test set.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4a39c355-8f43-4d8b-8302-f6c1e885f1ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 784)\n",
      "(70000,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the MNIST dataset\n",
    "mnist = fetch_openml('mnist_784')\n",
    "X = mnist.data\n",
    "y = mnist.target.astype(int)\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5b61c2-aa2f-4b9b-b547-1cd4c4c3d04c",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/0v1CGNV.png)<br>\n",
    "- Fine-tune the learning rate and epochs (max iterations).\n",
    "- Calculate the accuracy for both the train set predictions and test set predictions, what happens per iteration?\n",
    "- Is the accurracy different? Did you expect this difference?\n",
    "\n",
    "Optional: Perform the same tasks but change the hidden_layer_sizes <br>\n",
    "\n",
    "Findings: ...<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5aff5e-b2fa-4e43-8470-9997e3217120",
   "metadata": {},
   "source": [
    "### Portfolio assignment 21\n",
    "30 min: Train a perceptron to predict one of the categorical columns of your own dataset.\n",
    "- Prepare the data:<br>\n",
    "    - <b>Note</b>: Some machine learning algorithms can not handle missing values. You will either need to: \n",
    "         - replace missing values (with the mean or most popular value). For replacing missing values you can use .fillna(\\<value\\>) https://pandas.pydata.org/docs/reference/api/pandas.Series.fillna.html\n",
    "         - remove rows with missing data.  You can remove rows with missing data with .dropna() https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.dropna.html <br>\n",
    "    - <b>Note</b>: Some machine learning algorithms can not handle categorical values. You will either need to:\n",
    "        -  To handle categorical data, you can use One-Hot Encoding to convert categories into binary columns with .get_dummies(<value(s)>). This creates a new column for each category\n",
    "- Split your dataset into training (70%) and testing (30%) sets. \n",
    "- Use your Perceptron to make predictions for both the train and test set.<br>\n",
    "<br>\n",
    "\n",
    "![](https://i.imgur.com/0v1CGNV.png)<br>\n",
    "- Fit a Perceptron model using your own selected feature columns.\n",
    "- Fine-tune the learning rate and epochs (max iterations). \n",
    "- Calculate the accuracy for both the train set predictions and test set predictions, what happens per iteration?\n",
    "- Is the accurracy different? Did you expect this difference?\n",
    "\n",
    "Optional: Perform the same tasks but change the hidden_layer_sizes <br>\n",
    "\n",
    "Findings: ...<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datascience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
