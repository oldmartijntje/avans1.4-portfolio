{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7cc94336308f6874",
   "metadata": {},
   "source": [
    "# Gemaakt op 19/05/2025 door martijn"
   ]
  },
  {
   "cell_type": "code",
   "id": "8458724ca6657ca3",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "import graphviz\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ec07f639374a71c5",
   "metadata": {},
   "source": [
    "# the imported functions"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "753fc7bde331c381",
   "metadata": {},
   "source": [
    "### Portfolio assignment 22\n",
    "30 min: Let Yolov8 do predictions on your own choosen dataset (look for a nice images dataset on Roboflow or Kaggle or....).\n",
    "- Load your data in and have a quick look\n",
    "- Let YOLO predict from one of your images the objects\n",
    "- Describe if the predictions are correct according to you, just by looking at the images.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50f2e3338b9e58",
   "metadata": {},
   "source": [
    "ik heb hier een car [hand gesture dataset](https://www.kaggle.com/datasets/adhoppin/hand-gestures-dataset).\n",
    "\n",
    "ik gok dat hij hierna niet goed zal werken op de foto's die ik hem ga geven. Maar ik denk dat hij wel goed zal werken op de supplied test dataset"
   ]
  },
  {
   "cell_type": "code",
   "id": "e99d2f882905e0f7",
   "metadata": {},
   "source": [
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get the current directory\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Construct the base path dynamically\n",
    "base_path = os.path.join(current_dir, 'train')\n",
    "\n",
    "# Get the first image file in the folder\n",
    "image_files = os.listdir(base_path)  # List all files in the folder\n",
    "\n",
    "print(\"Image files in the folder:\", len(image_files))  # Print the list of image files\n",
    "first_image_path = os.path.join(base_path, image_files[0])  # Get the path of the first image\n",
    "\n",
    "# Read the first image\n",
    "image = cv2.imread(first_image_path)\n",
    "\n",
    "# Convert from BGR (OpenCV) to RGB (matplotlib)\n",
    "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Display the first image\n",
    "plt.imshow(image_rgb)\n",
    "plt.axis('off')  # Hide axes for a cleaner look\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b1df889cd4f98491",
   "metadata": {},
   "source": [
    "nu hebbrn er de 1e foto gepakt :3\n",
    "\n",
    "peace out ;)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "95482ee39313b4cd",
   "metadata": {},
   "source": [
    "from sklearn.utils import shuffle\n",
    "import pandas as pd\n",
    "\n",
    "#Load the labels which are vectors with a reference to the image\n",
    "annotations = pd.read_csv('train/_annotations.csv')\n",
    "annotations = shuffle(annotations, random_state=34)\n",
    "annotations.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c820a2065d01763d",
   "metadata": {},
   "source": [
    "print(annotations.shape)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "829ff819b446f0ec",
   "metadata": {},
   "source": [
    "classes = annotations['class'].unique()\n",
    "print(classes)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c6ff351ad9566405",
   "metadata": {},
   "source": [
    "er zijn dus 14 verschillende gestures"
   ]
  },
  {
   "cell_type": "code",
   "id": "a697dadd160bcf41",
   "metadata": {},
   "source": [
    "annotations['class'].value_counts()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f3522e5426ed2489",
   "metadata": {},
   "source": [
    "from matplotlib import image\n",
    "for c in classes:\n",
    "    image_name = annotations[annotations['class'] == c].iloc[0,0]\n",
    "    gesture = image.imread(os.path.join('./train/', image_name))\n",
    "    plt.figure()\n",
    "    plt.imshow(gesture)\n",
    "    plt.title(f\"Example of class {c}\")\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "9bf9cebc29766cac",
   "metadata": {},
   "source": [
    "okay so now i will give them unofficial class Names"
   ]
  },
  {
   "cell_type": "code",
   "id": "f1902ee3f87ad5de",
   "metadata": {},
   "source": [
    "from matplotlib import image\n",
    "names = {\n",
    "    \"0\": \"Peace\",\n",
    "    \"1\": \"Walking\",\n",
    "    \"2\": \"Double Flat Hands\",\n",
    "    \"3\": \"Tower\",\n",
    "    \"4\": \"Pacman?\",\n",
    "    \"5\": \"Upwards Fist\",\n",
    "    \"6\": \"Me\",\n",
    "    \"7\": \"Point at Hand\",\n",
    "    \"8\": \"Point at Walking\",\n",
    "    \"9\": \"Magic Hands\",\n",
    "    \"10\": \"Fingerguns\",\n",
    "    \"11\": \"Flat Hand\",\n",
    "    \"12\": \"Chin Hold Point\",\n",
    "    \"13\": \"No Money\",\n",
    "}\n",
    "classes.sort()\n",
    "for c in classes:\n",
    "    image_name = annotations[annotations['class'] == c].iloc[0,0]\n",
    "    image = cv2.imread(os.path.join('./train/', image_name))\n",
    "    image_rgb = image\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Display the first image\n",
    "    plt.imshow(image_rgb)\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"Example of class {c}, {names[str(c)]}\")\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "4268a5ae825a6086",
   "metadata": {},
   "source": [
    "I made these calssnames myself. I had to improvice a little because the inverted colors make it a little bit harder to see  (the inverted colors is only an issue on pycharm)"
   ]
  },
  {
   "cell_type": "code",
   "id": "12fcfe5e8a46df5e",
   "metadata": {},
   "source": [
    "labels = {\n",
    "    0: \"Peace\",\n",
    "    1: \"Walking\",\n",
    "    2: \"Double Flat Hands\",\n",
    "    3: \"Tower\",\n",
    "    4: \"Pacman?\",\n",
    "    5: \"Upwards Fist\",\n",
    "    6: \"Me\",\n",
    "    7: \"Point at Hand\",\n",
    "    8: \"Point at Walking\",\n",
    "    9: \"Magic Hands\",\n",
    "    10: \"Fingerguns\",\n",
    "    11: \"Flat Hand\",\n",
    "    12: \"Chin Hold Point\",\n",
    "    13: \"No Money\",\n",
    "}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2cfba12d6f519ca8",
   "metadata": {},
   "source": [
    "I was too lazy to convert the above example yo be using intagers as `key`"
   ]
  },
  {
   "cell_type": "code",
   "id": "db66d7b5b0e56ff3",
   "metadata": {},
   "source": [
    "import matplotlib\n",
    "# matplotlib.use('TkAgg')\n",
    "boxes = {}\n",
    "images = {}\n",
    "\n",
    "print(annotations.head())\n",
    "\n",
    "for class_id in classes:\n",
    "    # get all the rows for the current class\n",
    "    print(f\"Processing class {class_id}...\")\n",
    "    target_rows = annotations[annotations['class'] == class_id]\n",
    "    print(f\"Number of rows for class {class_id}: {len(target_rows)}\")\n",
    "    # Check if there are any rows for the current class. If not, skip to the next class\n",
    "    if target_rows.empty:\n",
    "        print(f\"No data found for class {class_id}. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    # Search for first image on disk from the dataframe\n",
    "    image_found = False\n",
    "    for _, row in target_rows.iterrows():\n",
    "        file_name = row['filename']\n",
    "        image_path = os.path.join(base_path, file_name)\n",
    "\n",
    "        if not os.path.exists(image_path):\n",
    "            continue\n",
    "\n",
    "        print(f\"Found image {image_path} for class {class_id}.\")\n",
    "\n",
    "        # Lees de afbeelding\n",
    "        image = matplotlib.pyplot.imread(image_path)\n",
    "\n",
    "        if image is None:\n",
    "            print(f\"Failed to load image {image_path}. Trying next row...\")\n",
    "            continue\n",
    "        else:\n",
    "            image_found = True\n",
    "            break\n",
    "\n",
    "    if image_found:\n",
    "        print(f\"Image found AND read for class {class_id}: {image_path}\")\n",
    "        # Convert from BGR (OpenCV) to RGB (matplotlib)\n",
    "        image_rgb =image\n",
    "\n",
    "        images[class_id] = image_rgb\n",
    "        boxes[class_id] = [\n",
    "            int(row['xmin']),\n",
    "            int(row['xmax']),\n",
    "            int(row['ymin']),\n",
    "            int(row['ymax'])\n",
    "        ]\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "983fbb00a211b887",
   "metadata": {},
   "source": [
    "## Let's visualise the 5 different classes that exists with their bounding boxes in a image\n",
    "for class_id in classes:\n",
    "    xmin, xmax, ymin, ymax = boxes[class_id][0], boxes[class_id][1], boxes[class_id][2], boxes[class_id][3]\n",
    "    # img = cv2.cvtColor(images[class_id], cv2.COLOR_BGR2RGB)\n",
    "    img = images[class_id]\n",
    "    # print(images[class_id].shape)\n",
    "\n",
    "    plt.figure(figsize=(4, 6))\n",
    "    plt.title(\"Label \" + labels[class_id])\n",
    "    plt.imshow(img)\n",
    "    plt.gca().add_patch(plt.Rectangle((xmin, ymin), xmax-xmin, ymax-ymin, color='yellow', fill=False, linewidth=2))\n",
    "\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8855b943a6a27a25",
   "metadata": {},
   "source": [
    "from ultralytics import YOLO\n",
    "import PIL\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "import os\n",
    "import pathlib\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2c5aaa457e764dfd",
   "metadata": {},
   "source": [
    "# Load the YOLO v8 model\n",
    "model = YOLO(\"yolov8m.pt\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a5741c2601f121a3",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(80)\n",
    "random_num=np.random.randint(0, 100)\n",
    "example = os.path.join(base_path, image_files[random_num])  # Get the path of the first image"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1cf1affc4ef6d7dd",
   "metadata": {},
   "source": [
    "results = model.predict(source=example, save=True, conf=0.2, iou=0.2) # change conf and iou"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "beff200fb92ae73f",
   "metadata": {},
   "source": [
    "# Return the information (class, coordinates of the box and the confidence) of each predicted object\n",
    "result = results[0]\n",
    "for box in result.boxes:\n",
    "    class_id = result.names[box.cls[0].item()]\n",
    "    cords = box.xyxy[0].tolist()\n",
    "    cords = [round(x) for x in cords]\n",
    "    conf = round(box.conf[0].item(), 2)\n",
    "    print(\"Object type:\", class_id)\n",
    "    print(\"Coordinates:\", cords)\n",
    "    print(\"Probability:\", conf)\n",
    "    print(\"---\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "daa2a9dfb9494aa6",
   "metadata": {},
   "source": [
    "# Plotting the predicted results\n",
    "plot = results[0].plot()\n",
    "\n",
    "# Convert the plot from BGR to RGB\n",
    "plot = cv2.cvtColor(plot, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Create a larger figure size\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(plot)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "yeah that is not accurate xD",
   "id": "35fbc0e8f82ee7dd"
  },
  {
   "cell_type": "code",
   "id": "722bbea6f3e08c50",
   "metadata": {},
   "source": [
    "filename = os.path.basename(example)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2840657060f511e0",
   "metadata": {},
   "source": [
    "annotations[annotations['filename']==filename]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c409f8803261664e",
   "metadata": {},
   "source": [
    "# Find all matching rows in annotations for this filename\n",
    "matching_rows = annotations[annotations['filename'] == filename]\n",
    "\n",
    "# Construct the full image path\n",
    "image_path = os.path.join(base_path, filename)\n",
    "\n",
    "# Read and convert the image\n",
    "image = cv2.imread(image_path)\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB for Matplotlib\n",
    "\n",
    "# Plot the image\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(image)\n",
    "\n",
    "for index, row in matching_rows.iterrows():\n",
    "    xmin, xmax, ymin, ymax = row['xmin'], row['xmax'], row['ymin'], row['ymax']\n",
    "\n",
    "    plt.gca().add_patch(\n",
    "        plt.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin,\n",
    "                      edgecolor='yellow', fill=False, linewidth=2)\n",
    "    )\n",
    "\n",
    "    # Add the index number above the bounding box\n",
    "    plt.text(xmin, ymin - 5, f\"{index}\", color='yellow',\n",
    "             fontsize=12, backgroundcolor='none')\n",
    "\n",
    "plt.axis('off')  # Hide axes for a cl\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "21b99799bcb3f695",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the mapping from YOLO class IDs to the new custom label IDs\n",
    "yolo_to_custom = {\n",
    "    2: 1,  # Car -> Class ID 2 maps to 1\n",
    "    7: 2,  # Truck -> Class ID 7 maps to 2\n",
    "    0: 3,  # Person -> Class ID 0 maps to 3\n",
    "    1: 4,  # Bicycle -> Class ID 1 maps to 4\n",
    "    9: 5   # Traffic light -> Class ID 9 maps to 5\n",
    "}\n",
    "\n",
    "# Initialize a list to hold the rows of the DataFrame\n",
    "predictions_data = []\n",
    "\n",
    "# Example: Extract YOLO predictions and ground truth for each frame (this should come from results[0])\n",
    "for i, box in enumerate(results[0].boxes):  # Iterate through each prediction\n",
    "    frame = filename  # You would retrieve the frame name here\n",
    "\n",
    "    # Extract xywh (center_x, center_y, width, height)\n",
    "    center_x, center_y, width, height = box.xywh[0].int().tolist()  # Convert to integers\n",
    "\n",
    "    # Convert to xmin, ymin, xmax, ymax\n",
    "    xmin = int(center_x - width / 2)\n",
    "    ymin = int(center_y - height / 2)\n",
    "    xmax = int(center_x + width / 2)\n",
    "    ymax = int(center_y + height / 2)\n",
    "\n",
    "    # Convert class_id tensor to integer\n",
    "    class_id = box.cls.int().item()  # Convert class tensor to integer\n",
    "\n",
    "    # Map YOLO class_id to the custom label ID\n",
    "    custom_class_id = yolo_to_custom.get(class_id, -1)  # Get the custom label ID (-1 for unknown)\n",
    "\n",
    "    # Append the prediction data to the list, now without the class_label\n",
    "    predictions_data.append([frame, xmin, xmax, ymin, ymax, custom_class_id])\n",
    "\n",
    "# Convert the predictions data to a pandas DataFrame\n",
    "predictions_df = pd.DataFrame(predictions_data, columns=['frame', 'xmin', 'xmax', 'ymin', 'ymax', 'class_id'])\n",
    "\n",
    "# Show the resulting DataFrame\n",
    "predictions_df"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3cfecf0d2960dbbb",
   "metadata": {},
   "source": [
    "# Function to calculate IoU\n",
    "def compute_iou(pred_box, gt_box):\n",
    "    x1, y1, x2, y2 = max(pred_box[0], gt_box[0]), max(pred_box[1], gt_box[1]), min(pred_box[2], gt_box[2]), min(pred_box[3], gt_box[3])\n",
    "    inter_area = max(0, x2 - x1) * max(0, y2 - y1)\n",
    "    pred_area = (pred_box[2] - pred_box[0]) * (pred_box[3] - pred_box[1])\n",
    "    gt_area = (gt_box[2] - gt_box[0]) * (gt_box[3] - gt_box[1])\n",
    "    union_area = pred_area + gt_area - inter_area\n",
    "    return inter_area / union_area if union_area > 0 else 0"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9a1b0a1449f9dd5c",
   "metadata": {},
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "ground_truth_df = annotations[annotations['filename'] == filename]\n",
    "\n",
    "# List to hold indices, ground truth, and IoU values\n",
    "iou_info = []\n",
    "# Calculate IoU without applying a threshold\n",
    "for i, pred in predictions_df.iterrows():\n",
    "    frame = pred['frame']\n",
    "    pred_box = [pred['xmin'], pred['ymin'], pred['xmax'], pred['ymax']]\n",
    "    pred_class = pred['class_id']\n",
    "\n",
    "    # Find the corresponding ground truth\n",
    "    gt_boxes = ground_truth_df[ground_truth_df['filename'] == frame]\n",
    "\n",
    "    for j, gt in gt_boxes.iterrows():\n",
    "        gt_box = [gt['xmin'], gt['ymin'], gt['xmax'], gt['ymax']]\n",
    "        gt_class = gt['class']\n",
    "\n",
    "        # Calculate IoU between prediction and ground truth\n",
    "        iou = compute_iou(pred_box, gt_box)\n",
    "\n",
    "        # Store the index, ground truth, and IoU for all predictions\n",
    "        iou_info.append([i, j, pred_class, gt_class, iou])\n",
    "\n",
    "# Create DataFrame to show the IoU results with prediction and ground truth indices\n",
    "iou_df = pd.DataFrame(iou_info, columns=['prediction_index', 'ground_truth_index', 'pred_class_id', 'gt_class_id', 'iou'])\n",
    "\n",
    "# Now, we can calculate the confusion matrix for all predictions (no threshold)\n",
    "predicted_classes = iou_df['pred_class_id'].values\n",
    "actual_classes = iou_df['gt_class_id'].values\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(actual_classes, predicted_classes)\n",
    "\n",
    "# Visualize the confusion matrix using Seaborn\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Car', 'Truck', 'Person', 'Bicycle', 'Traffic Light'], yticklabels=['Car', 'Truck', 'Person', 'Bicycle', 'Traffic Light'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix (All Predictions)')\n",
    "plt.show()\n",
    "\n",
    "# Output the IoU values for all predictions\n",
    "print(\"\\nIoU per object:\")\n",
    "print(iou_df[['prediction_index', 'ground_truth_index', 'iou']])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Okay hij is dus 2 keer goed op img 1, en 1 keer fout op img 1. Laten we nu de hele test dataset nemen",
   "id": "a9a03caf6efdf674"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Load the labels which are vectors with a reference to the image\n",
    "annotations = pd.read_csv('valid/_annotations.csv')\n",
    "annotations = shuffle(annotations, random_state=34)\n",
    "annotations.head()"
   ],
   "id": "a2552617d1ea59ee",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# 1. Load validation annotations\n",
    "ann = pd.read_csv('valid/_annotations.csv')\n",
    "# we'll assume every row is one object; if you have multiple per image, that's fine\n",
    "\n",
    "# 2. YOLO model\n",
    "model = YOLO(\"yolov8m.pt\")\n",
    "\n",
    "# 3. Mapping from YOLO‐class → your custom class_id\n",
    "yolo_to_custom = {\n",
    "    2: 1,   # Car → Peace\n",
    "    7: 2,   # Truck → Walking\n",
    "    0: 3,   # Person → Double Flat Hands\n",
    "    1: 4,   # Bicycle → Tower\n",
    "    9: 5    # Traffic light → Pacman?\n",
    "}\n",
    "# (adjust to your real mapping)\n",
    "\n",
    "# 4. Prepare lists\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "# 5. Loop over each unique image in valid/\n",
    "for fname in ann['filename'].unique():\n",
    "    # run YOLO once per image\n",
    "    res = model.predict(source=os.path.join('valid', fname), conf=0.2, iou=0.2)[0]\n",
    "\n",
    "    # get all GT for this image\n",
    "    gt_rows = ann[ann['filename'] == fname]\n",
    "    # collect all GT class IDs\n",
    "    gt_classes = gt_rows['class'].tolist()\n",
    "\n",
    "    # for each predicted box:\n",
    "    for b in res.boxes:\n",
    "        pred_yolo_id = int(b.cls[0].item())\n",
    "        pred_custom = yolo_to_custom.get(pred_yolo_id, -1)\n",
    "        # Here you could match by IoU to a specific GT box\n",
    "        # but for a simple overall confusion we'll just pair every pred vs. every GT\n",
    "        # (or pick the highest‐IoU GT if you want one‐to‐one)\n",
    "        for gt in gt_classes:\n",
    "            y_true.append(gt)\n",
    "            y_pred.append(pred_custom)\n",
    "\n",
    "# 6. Compute confusion matrix\n",
    "labels = sorted(set(y_true) | set(y_pred))\n",
    "cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "\n",
    "# 7. Plot it\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm, annot=True, fmt='d',\n",
    "            xticklabels=labels, yticklabels=labels,\n",
    "            cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Validation Confusion Matrix')\n",
    "plt.show()\n"
   ],
   "id": "79d29c7e700caa82",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "hmmm, dat ziet er niet al te best uit xDD\n",
   "id": "e59d4bf27b6f0aa5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "nu heb ik zin om random fotos er doorheen te gooien xD",
   "id": "12cf58e243d9a2f6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# 1. Load your YOLOv8 model once\n",
    "model = YOLO(\"yolov8m.pt\")\n",
    "\n",
    "# 2. Path to your folder of images\n",
    "me_dir = \"me\"\n",
    "# adjust extensions if you have other types\n",
    "image_files = [\n",
    "    f for f in os.listdir(me_dir)\n",
    "    if f.lower().endswith((\".jpg\", \".jpeg\", \".png\"))\n",
    "]\n",
    "\n",
    "# 3. Loop through each image, run predict, and plot\n",
    "for img_name in image_files:\n",
    "    img_path = os.path.join(me_dir, img_name)\n",
    "\n",
    "    # run inference (you can tweak conf and iou thresholds)\n",
    "    results = model.predict(source=img_path, conf=0.2, iou=0.2)\n",
    "    res = results[0]\n",
    "\n",
    "    # get the plotted image (with boxes & labels)\n",
    "    plot = res.plot()\n",
    "    # convert from BGR (OpenCV) to RGB (matplotlib)\n",
    "    plot = cv2.cvtColor(plot, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # display\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(plot)\n",
    "    plt.title(f\"Predictions for {img_name}\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n"
   ],
   "id": "902eb809eb4e504b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## findings\n",
    "\n",
    "over all i see that it recognises people quite accurately. And so does it recognise ducks.\n",
    "\n",
    "BUt the hand gestures, or items, it is not the best at it.\n",
    "\n",
    "still impressiver though"
   ],
   "id": "3607307e14237f03"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
